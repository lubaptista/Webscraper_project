# Web Scraper - webscraper.io

> Projeto de estudo para aprender web scraping em Python de forma modular e profissional.

## ğŸ¯ Objetivo

O scraper coleta dados de tabelas do site:

[https://webscraper.io/test-sites/tables](https://webscraper.io/test-sites/tables)

O objetivo Ã©:
- entender scraping de listas e tabelas
- praticar BeautifulSoup
- estruturar scraping em mÃ³dulos
- salvar dados em JSON e CSV
- escrever testes automatizados

---

## ğŸ—‚ï¸ Estrutura do Projeto

webscraper_project/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py     â†’ URLs, delays, user-agents
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/      â†’ pasta onde o script guarda os dados processados ao final da execuÃ§Ã£o
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py         â†’ orquestra o scraper
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ network.py      â†’ requisiÃ§Ãµes HTTP
â”‚   â”œâ”€â”€ parser.py       â†’ parse HTML (BeautifulSoup)
â”‚   â”œâ”€â”€ extractor.py    â†’ extrai dados das tabelas
â”‚   â”œâ”€â”€ navigator.py    â†’ lÃ³gica de paginaÃ§Ã£o (neste site, vazio)
â”‚   â”œâ”€â”€ storage.py      â†’ salva JSON ou CSV
â”‚   â”œâ”€â”€ utils.py        â†’ funÃ§Ãµes genÃ©ricas
â”‚   â””â”€â”€ logger.py       â†’ logging em arquivo
â”‚
â”œâ”€â”€ tests/              â†’ testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_extractor.py
â”‚   â””â”€â”€ test_navigator.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

---

## Tecnologias/Requisitos

- Python 3
- requests
- BeautifulSoup
- lxml

---

## ğŸš€ InstalaÃ§Ã£o

Clone o repositÃ³rio ou crie a pasta manualmente.

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Como Rodar

Execute o arquivo principal:
```bash
python -m src.main
```

VocÃª verÃ¡ algo assim no terminal:

```bash
Iniciando scraper do site webscraper.io/test-sites/tables ...
Scraping URL: https://webscraper.io/test-sites/tables
Coletadas 2 tabelas na pÃ¡gina.
Scraping concluÃ­do!
```

E os arquivos serÃ£o salvos em:

```bash
data/processed/tables.json
data/processed/tables.csv

```